{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_CNN_classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAHfjfRfLkIT"
      },
      "source": [
        "# Hands-on: Classification of Liver With or Without Tumor on CT Images\n",
        "## 02 CNN Classification\n",
        "Dataset reference: [Medical Segmentation Decathlon](http://medicaldecathlon.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgMOKcgTCB9G"
      },
      "source": [
        "## 0\\. Change to GPU\n",
        "開啟此 notebook 後，請先至左上角「執行階段」內點選\n",
        "「變更執行階段類型」，並將硬體加速器改為「GPU」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qCqeLPsMFvL"
      },
      "source": [
        "## 1\\. Prepare the Enviornment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKqdLA3z73NK"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from google.colab import drive\n",
        "from random import shuffle\n",
        "from collections import Counter\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from random import randint\n",
        "from scipy.ndimage import zoom\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyWG8pcZfuPF"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP6FDom-Mlu3"
      },
      "source": [
        "## 2\\. Download the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNVkzdu6stw8"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnEVcrQQsvgZ"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLZxIs6XMq2_"
      },
      "source": [
        "# unzip the file\n",
        "if not os.path.exists(r\"./liver_classification\") and os.path.exists(r\"./liver_classification.zip\"):\n",
        "    !unzip liver_classification.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyywhdkBN-Xx"
      },
      "source": [
        "## 3\\. Import and View the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA9lOJYNnyWe"
      },
      "source": [
        "### 3-1. Check the dataset\n",
        "Let's check the amount of images we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0zDSB2myo8J"
      },
      "source": [
        "# Set the path\n",
        "data_dir = './liver_classification'\n",
        "image_dir = os.path.join(data_dir, 'crop_image')\n",
        "label_dir = os.path.join(data_dir, 'crop_label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkfFLwLlyzBK"
      },
      "source": [
        "# Check how much data we have\n",
        "print(\"Number of images:\", len(os.listdir(image_dir)))\n",
        "print(\"Number of labels:\", len(os.listdir(label_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY_6ZIGe7et7"
      },
      "source": [
        "We have 130 pairs of CT images and labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20H-OAjSn61-"
      },
      "source": [
        "### 3-2. Separate the images 分成訓練、驗證、測試\n",
        "Then, we need to split the 130 data into training, validation, and testing sets. \\\n",
        "You can decide the amount of each set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsvKdi7TApjR"
      },
      "source": [
        "# Separate data into training, validation, and testing set with ratio [0.6, 0.2, 0.2]\n",
        "total_filelist = os.listdir(image_dir)    #將圖片資料夾中的圖片檔案名全部存到total_filelist\n",
        "shuffle(total_filelist)     #將total_filelist隨機排序\n",
        "\n",
        "############### change here #################\n",
        "train_n = 78\n",
        "valid_n = 26\n",
        "test_n = 26\n",
        "############### change here #################\n",
        "\n",
        "train_list = total_filelist[:train_n]\n",
        "valid_list = total_filelist[train_n : train_n+valid_n]\n",
        "test_list = total_filelist[train_n + valid_n : train_n + valid_n + test_n]\n",
        "\n",
        "print(\"{} data for training, list: {}\".format(len(train_list), train_list))\n",
        "print(\"{} data for validation, list: {}\".format(len(valid_list), valid_list))\n",
        "print(\"{} data for testing, list: {}\".format(len(test_list), test_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCRX06mAuIrh"
      },
      "source": [
        "### 3-3. Load and preprocess the images\n",
        "在我們分離數據之後，我們必須加載數據並進行前處理，以便 \n",
        "\n",
        "\n",
        "1.   調整數據格式以適應模型\n",
        "2.   進行圖像處理以避免無用信息\n",
        "\n",
        "下面是圖像預處理和數據加載的兩個基本函數\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaQiAN5q2Ylg"
      },
      "source": [
        "# function of image resampling\n",
        "def resample(image, label, output_shape=(224, 224)):\n",
        "  # resample the image (make all images to the assigned size)\n",
        "  resize_factor_x = output_shape[0] / np.shape(image)[0]\n",
        "  resize_factor_y = output_shape[1] / np.shape(image)[1]\n",
        "  image = zoom(image, (resize_factor_x, resize_factor_y), order=0, mode='nearest')\n",
        "  label = zoom(label, (resize_factor_x, resize_factor_y), order=0, mode='nearest')\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XytfIuJp9oj"
      },
      "source": [
        "下面的函數執行數據加載和前處理。 \\\n",
        "前處理包括： \n",
        "\n",
        "*   **裁剪**：去除肝臟邊界框外的區域，您可以決定是否對圖像進行裁剪。\n",
        "*   **重❤️採樣**：將圖像縮放到特定的形狀，我們模型的輸入形狀是(224, 224)（導入模型的時候可以找到），所以我們要把圖像重採樣成(224, 224)。\n",
        "*   **加窗Windowin**：調整圖像的亮度和對比度，此過程僅對CT圖像有效，您可以針對不同的窗寬和窗位調整該值。\n",
        "*   **正規化Normalization**：將每個像素上的值更改為 (0, 1)。\n",
        "*   **掩蔽Masking**：將肝臟以外的區域改為0。您可以決定是否對圖像進行掩蔽。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeJ6QBCluyge"
      },
      "source": [
        "# function of data loading and preprocessing\n",
        "def load_data(image_dir, label_dir, file_list, output_shape=(224, 224), channel=3, window_range=(-50, 200), perform_crop=True, perform_mask=True):\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  #您可以決定是否對圖像進行裁剪。如果要剪裁，就除肝臟邊界框外的區域。\n",
        "  if perform_crop:\n",
        "    threshold_tumor = 0.001\n",
        "    threshold_liver = 0.04\n",
        "  else:\n",
        "    threshold_tumor = 0.002\n",
        "    threshold_liver = 0.08\n",
        "\n",
        "  #我要利用檔名，將每張圖片讀取出來\n",
        "  for filename in tqdm(file_list):      #tqdm：進度條\n",
        "    ori_image = nib.load(os.path.join(image_dir, filename)).get_fdata()\n",
        "    ori_label = nib.load(os.path.join(label_dir, filename)).get_fdata()\n",
        "\n",
        "    #剪裁（？？）\n",
        "    # Preprocessing - cropping\n",
        "    if perform_crop:\n",
        "      x_min = np.min(np.where(ori_label != 0)[0])\n",
        "      x_max = np.max(np.where(ori_label != 0)[0])\n",
        "      y_min = np.min(np.where(ori_label != 0)[1])\n",
        "      y_max = np.max(np.where(ori_label != 0)[1])\n",
        "      ori_image = ori_image[x_min:x_max, y_min:y_max, :]\n",
        "      ori_label = ori_label[x_min:x_max, y_min:y_max, :]\n",
        "\n",
        "\n",
        "    for idx in range(ori_image.shape[2]):\n",
        "      if not np.max(ori_label[:, :, idx]) == 0:\n",
        "        # Preprocessing - resampling\n",
        "        image_2d, label_2d = resample(ori_image[:, :, idx], ori_label[:, :, idx], output_shape=output_shape)\n",
        "        # Preprocessing - windowing\n",
        "        image_2d = np.clip(image_2d, window_range[0], window_range[1])\n",
        "        # Preprocessing - normalization\n",
        "        image_2d = (image_2d - np.min(image_2d))/(np.max(image_2d) - np.min(image_2d))\n",
        "        # Preprocessing - masking\n",
        "        if perform_mask:\n",
        "          image_2d[np.where(label_2d == 0)] = 0\n",
        "\n",
        "        if np.max(label_2d) == 2 and np.count_nonzero(label_2d == 1) > output_shape[0]**2*threshold_tumor:\n",
        "          X.append(image_2d)\n",
        "          y.append(1)\n",
        "        elif np.max(label_2d) == 1 and np.count_nonzero(label_2d == 1) > output_shape[0]**2*threshold_liver:\n",
        "          X.append(image_2d)\n",
        "          y.append(0)\n",
        "\n",
        "  X = np.array(X)\n",
        "  stacked_X = np.stack((X,)*channel, axis=-1)\n",
        "  print(\"We got {} 2D images with {}\".format(len(y), Counter(y)))\n",
        "  y = np.array(y)\n",
        "  print(\"Done loading data with X shape = {}, y shape = {}\".format(stacked_X.shape, y.shape))\n",
        "\n",
        "  return stacked_X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4J8RLB3uG7k"
      },
      "source": [
        "您可以在此處調整一些用於前處理的參數。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89dzEhv-C8J4"
      },
      "source": [
        "# Load data and perform image processing\n",
        "############### change here #################\n",
        "output_shape = (224, 224)\n",
        "channel = 3\n",
        "window_range = (-50, 200)\n",
        "perform_crop = True\n",
        "perform_mask = True\n",
        "############### change here #################\n",
        "\n",
        "train_X, train_y = load_data(\n",
        "    image_dir, label_dir, train_list, \n",
        "    output_shape=output_shape, \n",
        "    channel=channel, \n",
        "    window_range=window_range,\n",
        "    perform_crop=perform_crop, \n",
        "    perform_mask=perform_mask\n",
        ")\n",
        "\n",
        "valid_X, valid_y = load_data(\n",
        "    image_dir, label_dir, valid_list, \n",
        "    output_shape=output_shape, \n",
        "    channel=channel, \n",
        "    window_range=window_range,\n",
        "    perform_crop=perform_crop, \n",
        "    perform_mask=perform_mask\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUyo9V65vVd5"
      },
      "source": [
        "### 3-4. Visualize the data\n",
        "After loading the data, let's have a look at what `train_X`, `train_y`, `valid_X`, `valid_y` we got."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQbOmJiou7N1"
      },
      "source": [
        "# function of plotting data randomly\n",
        "def plot_image(X, y, row, col):\n",
        "  ax = []\n",
        "  fig = plt.figure(figsize=(3*col, 3*row))\n",
        "\n",
        "\n",
        "  for i in range(row*col):\n",
        "    value = randint(0, X.shape[0]-1)\n",
        "    image_plot = X[value, :, :, 0]\n",
        "    ax.append(fig.add_subplot(row, col, i+1))\n",
        "    ax[i].set_title(\"Label: {}\".format(y[value]))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image_plot, cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuAtTZklwBcP"
      },
      "source": [
        "We can randomly pick some examples from training or validation sets to see the images.\\\n",
        "You can change how many images to show at each row or column run the code repeatly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY0V8ar0-vP-"
      },
      "source": [
        "############### change here #################\n",
        "row = 1\n",
        "col = 5\n",
        "############### change here #################\n",
        "\n",
        "plot_image(train_X, train_y, row, col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z-urt6y1StG"
      },
      "source": [
        "### 3-5. Fit the data into generator with augmentation\n",
        "We can perform augmentation to increase the variability of the training data. \\\n",
        "This code shows the original parameters (aka without any augmentation). \\\n",
        "You can try different number. For example, setting `rotation_range`=10, `width_shift_range`=0.1, `height_shift_range`=0.1, `shear_range`=0.1, `zoom_range`=0.1) \\\n",
        "There's no \"best\" setting for deep learning. All you can do is running several experiment to find the pattern. \\\n",
        "You can check more detail at [ImageDataGenerator class](https://keras.io/api/preprocessing/image/#imagedatagenerator-class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCueKh2vhSyK"
      },
      "source": [
        "# Set the augmentation parameters and fit the training data\n",
        "############### change here #################\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.0,\n",
        "    height_shift_range=0.0,\n",
        "    shear_range=0.0,\n",
        "    zoom_range=0.0,\n",
        "    fill_mode=\"constant\",\n",
        "    cval=0\n",
        ")\n",
        "############### change here #################\n",
        "datagen.fit(train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24NfcDU-fp9T"
      },
      "source": [
        "## 4\\. Build the Model\n",
        "We finished preparing the data! \\\n",
        "It's time to build a CNN model for classification if the CT iamge contains a liver tumor or not.\\\n",
        "Here we use MobileNet provided by Keras Applications because this may be the fastest model. \\\n",
        "You can also visit [Keras Applications](https://keras.io/api/applications/) to try different model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrp0BBBUSwUv"
      },
      "source": [
        "### 4-1. Load the model with pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKS_EpMY-ziT"
      },
      "source": [
        "from tensorflow.keras.applications import MobileNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOubNv0m-5tT"
      },
      "source": [
        "# Load the model and add layers for binary classification output\n",
        "base_model = MobileNet(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000\n",
        ")\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXIC75bhkDWY"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-4),\n",
        "      loss=\"binary_crossentropy\",\n",
        "      metrics=[\"accuracy\"],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDWoG3zwP5kD"
      },
      "source": [
        "# [optional] Plot the model (method 1)\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojqx5Xs8xWsN"
      },
      "source": [
        "# [optional] Plot the model (method 2)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXwFBGiJwo4E"
      },
      "source": [
        "### 4-2. Start training model\n",
        "We start training the model here. \\\n",
        "Please notice that this might take a while. You can also adjust the number of epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVdUuPvCkKjS"
      },
      "source": [
        "# Set the epochs and batch size, then train the model\n",
        "############### change here #################\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "############### change here #################\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
        "    steps_per_epoch=len(train_X)/batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(valid_X, valid_y)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM91xu4nxqpE"
      },
      "source": [
        "When we finished training, we can take a look at the changes of  loss and accuracy on training and validation data during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gt8r4OoUA-2"
      },
      "source": [
        "# Plot loss and accuracy\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Train History')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Train History')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMcujxCffGKU"
      },
      "source": [
        "## 5\\. Evaluate the Test Data\n",
        "We've done training the model. \\\n",
        "Now it's time to see how the model perform on testing data.\\\n",
        "Firstly, let's load the testing data using the same method when we load the training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr90nenUQHsH"
      },
      "source": [
        "# Load test data\n",
        "test_X, test_y = load_data(\n",
        "    image_dir, label_dir, test_list, \n",
        "    output_shape=output_shape, \n",
        "    channel=channel, \n",
        "    window_range=window_range,\n",
        "    perform_crop=perform_crop, \n",
        "    perform_mask=perform_mask\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rltyrmoNyRkv"
      },
      "source": [
        "Here we perform the trained mdoel on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKm9c9SrR10f"
      },
      "source": [
        "# Predict the test data\n",
        "predict_y = model.predict(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv7aWrpEyVcN"
      },
      "source": [
        "Then, we can see the classification results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WXI7yjYkml1"
      },
      "source": [
        "# Plot the ROC curve of the test results\n",
        "plt.figure()\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "fpr, tpr, _ = roc_curve(test_y, predict_y)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label='AUC = {}'.format(roc_auc))\n",
        "\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1.05])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KegaNaGazLZ8"
      },
      "source": [
        "We now turn the result into binary result, and make the comparison on the groundtruths by the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZiYS_9ZkIoP"
      },
      "source": [
        "# Print the confusion matrix of the binray classification\n",
        "predict_y[predict_y >= 0.5] = 1\n",
        "predict_y[predict_y < 0.5] = 0\n",
        "\n",
        "print(confusion_matrix(test_y, predict_y, labels=[1, 0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcLWNDS6zXz7"
      },
      "source": [
        "Then, we can check the sensitivity and specificity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02wRnd0eyhH_"
      },
      "source": [
        "# Calculate the sensitivity and specificity\n",
        "TP = confusion_matrix(test_y, predict_y, labels=[1, 0])[0, 0]\n",
        "FP = confusion_matrix(test_y, predict_y, labels=[1, 0])[1, 0]\n",
        "FN = confusion_matrix(test_y, predict_y, labels=[1, 0])[0, 1]\n",
        "TN = confusion_matrix(test_y, predict_y, labels=[1, 0])[1, 1]\n",
        "print(\"True positive: {}\".format(TP))\n",
        "print(\"False positive: {}\".format(FP))\n",
        "print(\"False negative: {}\".format(FN))\n",
        "print(\"True negative: {}\".format(TN))\n",
        "\n",
        "\n",
        "############### your code here #################\n",
        "sensitivity =\n",
        "specificity =\n",
        "############### your code here #################\n",
        "\n",
        "print(\"Sensitivity: {}\".format(sensitivity))\n",
        "print(\"Specificity: {}\".format(specificity))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}